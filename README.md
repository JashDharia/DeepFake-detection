# Counteracting Misinformation by AI Using Deepfake Detection Algorithms ğŸ¤–ğŸ”

**Team**:  
- Jash Dharia  
- Austin Rodrigues  
- Abhishek Shinde  
- Amol Borkar  

## ğŸš€ Introduction

Recent advancements in **Generative AI** have enabled the creation of **Deepfake** images and videos (using tools like **FaceSwap**) that can easily circulate on social media. This technology poses risks as malicious actors can impersonate others and harm reputations. ğŸ˜ˆğŸ‘¥

Our **model** ğŸ§  is designed to be part of a **content moderation pipeline**, identifying whether an image uploaded by a user is a deepfake or not. The primary stakeholders for this project are:

- **Social Media Platforms** ğŸ“± (Content Moderation)  
- **Law Enforcement** ğŸ‘®â€â™‚ï¸  

We followed a **conventional deep-learning approach** and developed a model from scratch that achieved **84.6% test accuracy**. ğŸ¯

## ğŸ“š Literature Review

Our research revealed that **Convolutional Neural Networks (CNNs)** are the most widely-used method for deepfake detection. Many studies combine CNNs with techniques like:

- **Attention maps** ğŸ‘ï¸  
- **Frequency extractors** ğŸ¶

CNNs excel at **learning image features** and are well-suited for tasks with limited data. Since **Social Media Platforms** are our primary stakeholders, we aimed to create a model that balances:

- **Excellent inference speeds** âš¡ to handle millions of user-uploaded images daily
- **Explainability** ğŸ“Š for classification results

## ğŸ“Š Data and Methods

### Data
We primarily worked with **image data** ğŸ–¼ï¸ and used publicly available datasets:

- **Diverse Fake Face Dataset** (msu.edu)  
- **OpenForensics: In-The-Wild Dataset [V.1.0.0]**  

Due to **limited computing resources** ğŸ’», we constructed a custom dataset from **DFFD** consisting of:

- 10,000 **real** images ğŸ–¼ï¸  
- 6,900 **deepfakes** ğŸ”´

### Methods
#### Preprocessing Steps:
1. **Face detection** using a **pre-trained model** ğŸ‘€
2. **Center-cropping** images to 256x256 resolution ğŸ–¼ï¸  
3. **Normalization** of image data  

We experimented with various **CNN architectures** (AlexNet, LeNet, ResNet), training for **40 epochs** â³ with a batch size of 75 on 16K images.

## ğŸ“ˆ Results

### Performance Overview:
- **AlexNet**:
  - **98% training accuracy** ğŸ¯
  - **84.6% test accuracy** âœ…

- **LeNet**:
  - **81% test accuracy** ğŸ“Š

- **ResNet**:
  - Surprisingly, **46% accuracy** despite the high parameter count. This underperformance could be due to insufficient training data and epochs. ğŸ¤·â€â™‚ï¸
![180d1d42-ee03-47a0-8784-9c2b956871ae](https://github.com/user-attachments/assets/65243cc0-7583-4296-b572-8d7adf8a7f86)

![858ddd91-6200-44c1-9c9c-2aae9d7c06da](https://github.com/user-attachments/assets/b1c52584-2a41-4d7f-b862-c4db49d066a3)


![6e7bf27f-36fb-41bf-91e0-5985cfefadee](https://github.com/user-attachments/assets/73f99038-8b53-4c7f-9433-e83d7b8e42d7)


## ğŸ’¬ Discussion

Our model must **learn deepfake artifacts** ğŸ” rather than just generic image features. Although our model works as an early-stage **filter** for content moderation, testing it on **real-world data** from social media platforms is necessary to enhance generalization. ğŸŒ

